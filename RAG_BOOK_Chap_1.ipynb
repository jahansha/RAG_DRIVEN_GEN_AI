{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGncNlPeEeLb2x9XUmiv7M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahansha/RAG_DRIVEN_GEN_AI/blob/main/RAG_BOOK_Chap_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3YAxj51j1566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "617172f9-f08c-45a2-a889-a6df16f0f4d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.69.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Downloading openai-1.69.0-py3-none-any.whl (599 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/599.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.1/599.1 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "Successfully installed openai-1.69.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup API Key storage"
      ],
      "metadata": {
        "id": "juedKpEK1-Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeKVf0ah2e_m",
        "outputId": "bd90f9a3-87fd-410c-9bfa-8ae6215e3b0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY = f.readline().strip()\n",
        "f.close()\n",
        "#API_KEY"
      ],
      "metadata": {
        "id": "nXaLY9LU27ie"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The openai key"
      ],
      "metadata": {
        "id": "StPV3Kv96NA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "os.environ['OPENAI_API_KEY']=API_KEY\n",
        "openai.api_key=os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "nbV1uSSr6Sd7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "gptmodel=\"gpt-4o\"\n",
        "\n",
        "def call_llm_with_full_text(itext):\n",
        "    # Join all lines to form a single string\n",
        "    text_input = '\\n'.join(itext)\n",
        "    prompt = f\"Please elaborate on the following content:\\n{text_input}\"\n",
        "\n",
        "    try:\n",
        "      response = client.chat.completions.create(\n",
        "         model=gptmodel,\n",
        "         messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert Natural Language Processing exercise expert.\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"1.You can explain read the input and answer in detail\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "         ],\n",
        "         temperature=0.1  # Add the temperature parameter here and other parameters you need\n",
        "        )\n",
        "      return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return str(e)"
      ],
      "metadata": {
        "id": "7ytKHR4YBH8p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "def print_formatted_response(response):\n",
        "    # Define the width for wrapping the text\n",
        "    wrapper = textwrap.TextWrapper(width=80)  # Set to 80 columns wide, but adjust as needed\n",
        "    wrapped_text = wrapper.fill(text=response)\n",
        "\n",
        "    # Print the formatted response with a header and footer\n",
        "    print(\"Response:\")\n",
        "    print(\"---------------\")\n",
        "    print(wrapped_text)\n",
        "    print(\"---------------\\n\")"
      ],
      "metadata": {
        "id": "QcaMVtd9BOaV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERATION WITHOUT AUGMENTATION"
      ],
      "metadata": {
        "id": "3kx820DSBriZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"define a rag store\"\n",
        "# Call the function and print the result\n",
        "llm_response = call_llm_with_full_text(query)\n",
        "print_formatted_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hULW8JhBVnO",
        "outputId": "84632a62-7d2b-4a84-c33e-60269f085cc9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "---------------\n",
            "The term \"a rag store\" refers to a type of shop or business that primarily deals\n",
            "with the buying and selling of rags, which are typically pieces of old or\n",
            "discarded cloth. These stores often collect, sort, and sell rags for various\n",
            "purposes, such as cleaning, recycling, or repurposing into new products.\n",
            "Historically, rag stores played a significant role in the recycling industry,\n",
            "especially before the widespread availability of synthetic materials and modern\n",
            "recycling methods.  In a broader sense, a rag store might also deal in second-\n",
            "hand clothing or textiles, offering a sustainable option for consumers looking\n",
            "to purchase affordable clothing or materials. These stores contribute to\n",
            "reducing waste by extending the life cycle of textiles and promoting the reuse\n",
            "of materials.  The concept of a rag store can also be metaphorically extended to\n",
            "describe any business or operation that deals with used or second-hand goods,\n",
            "emphasizing the importance of recycling and sustainability in today's economy.\n",
            "---------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}